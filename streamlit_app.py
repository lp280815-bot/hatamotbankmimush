# streamlit_app.py
# -*- coding: utf-8 -*-
import io, re, os, json
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st
from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Font

# ---------------- UI (RTL + ×‘×¡×™×¡) ----------------
st.set_page_config(page_title="×”×ª×××•×ª ×œ×§×•×—×•×ª â€“ OV/RC + ×”×•×¨××•×ª ×§×‘×¢ + ×”×¢×‘×¨×•×ª", page_icon="âœ…", layout="centered")
st.markdown("""
<style>
  html, body, [class*="css"] { direction: rtl; text-align: right; }
  .block-container { padding-top: 1rem; }
</style>
""", unsafe_allow_html=True)

st.title("×”×ª×××•×ª ×œ×§×•×—×•×ª â€“ OV/RC + ×”×•×¨××•×ª ×§×‘×¢ (VLOOKUP ×§×‘×•×¢ + ×©××™×¨×”) + ×”×¢×‘×¨×•×ª (××¡' ×”×ª×××” 3)")

# -------- ×›×œ×œ×™ VLOOKUP ×‘×¨×™×¨×ª-××—×“×œ --------
RAW_NAME_MAP = {
    "×‘×–×§ ×‘×™× ×œ××•××™ ×‘": 30006,
    "×¤×¨×™ ×™×¨×•×—× ×—×‘'": 34714,
    "×¡×œ×§×•× ×™×©×¨××œ ×‘×¢": 30055,
    "×‘×–×§-×”×•×¨××•×ª ×§×‘×¢": 34746,
    "×“×¨×š ××¨×¥ ×”×™×™×•×•×™": 34602,
    "×’×œ×•×‘×¡ ×¤×‘×œ×™×©×¨ ×¢": 30067,
    "×¤×œ××¤×•×Ÿ ×ª×§×©×•×¨×ª": 30030,
    "××¨×›×– ×”×›×•×›×‘×™×•×ª": 30002,
    "×¢.××©×“×•×“-××¡×™×": 30056,
    "×.×©.×(×‘×¡\"×“)××—×–": 30050,
    "××•.×¤×™.×’'×™(×.×›)": 30047,
    "×¨×©×•×ª ×”××›×™×¤×” ×•×”": "67-1",
    "×§×•×œ ×‘×™×– ××™×œ× ×™×•": 30053,
    "×¤×¨×™×•×¨×™×˜×™ ×¡×•×¤×˜×•": 30097,
    "××™× ×˜×¨× ×˜ ×¨×™××•×Ÿ": 34636,
    "×¢×•\"×“× ×™×ª ×‘×¢\"×": 30018,
    "×¢×™×¨×™×™×ª ×¨××ª ×’×Ÿ": 30065,
    "×¤×– ×—×‘×¨×ª × ×¤×˜ ×‘×¢": 34811,
    "×™×©×¨××›×¨×˜": 28002,
    "×—×‘×¨×ª ×”×—×©××œ ×œ×™×©": 30015,
    "×”×¤× ×™×§×¡ ×‘×™×˜×•×—": 34686,
    "××™××•×Ÿ ×™×©×™×¨ ××§×‘": 34002,
    "×©×œ××” ×˜×¤×¨": 30247,
    "× ××¨×•×“ ×ª×‘×•×¨ ×¢×•×¨×š-×“×™×Ÿ": 30038,
    "×¢×™×¨×™×™×ª ×‘×™×ª ×©××©": 34805,
    "×¤×– ×§××¢×•× ××•×ª ×•×": 34811,
    "×”×•\"×§ ×”×œ×•' ×¨×‘×™×ª": 8004,
    "×”×•\"×§ ×”×œ×•×•××” ×§×¨×Ÿ": 23001,
    # ×›×œ×œ×™×™×
    "×¢×™×¨×™×™×ª ××©×“×•×“": 30056,
    "×™×©×¨××›×¨×˜ ××•×¨": 34002,
}
BASE_AMOUNT_MAP = {
    8520.0: 30247,    # ×©×œ××” ×˜×¤×¨
    10307.3: 30038,   # × ××¨×•×“ ×ª×‘×•×¨ ×¢×•"×“
}

# -------- ××–×”×™ ×¢××•×“×•×ª ××¤×©×¨×™×™× (×¢×‘×¨×™×ª/×•×¨×™××¦×™×•×ª) --------
MATCH_COL_CANDS = ["××¡.×”×ª×××”","××¡. ×”×ª×××”","××¡ ×”×ª×××”","××¡×¤×¨ ×”×ª×××”","×”×ª×××”"]
BANK_CODE_CANDS = ["×§×•×“ ×¤×¢×•×œ×ª ×‘× ×§","×§×•×“ ×¤×¢×•×œ×”","×§×•×“ ×¤×¢×•×œ×ª"]
BANK_AMT_CANDS  = ["×¡×›×•× ×‘×“×£","×¡×›×•× ×“×£","×¡×›×•× ×‘×‘× ×§","×¡×›×•× ×ª× ×•×¢×ª ×‘× ×§"]
BOOKS_AMT_CANDS = ["×¡×›×•× ×‘×¡×¤×¨×™×","×¡×›×•× ×‘×¡×¤×¨","×¡×›×•× ×¡×¤×¨×™×"]
REF_CANDS       = ["××¡××›×ª× 1","××¡××›×ª×1","××¡××›×ª×","××¡××›×ª×”"]
DATE_CANDS      = ["×ª××¨×™×š ×××–×Ÿ","×ª××¨×™×š ×¢×¨×š","×ª××¨×™×š"]
DETAILS_CANDS   = ["×¤×¨×˜×™×","×ª×™××•×¨","×©× ×¡×¤×§"]

# ×”×ª×××” 3 â€“ ×¢××•×“×•×ª ×‘×§×•×‘×¥ ×”×¢×–×¨
AUX_DATE_KEYS   = ["×ª××¨×™×š","×¤×¨×™×§×”"]       # "×ª××¨×™×š ×¤×¨×™×§×”" (×ª××¨×™×š+×©×¢×”)
AUX_AMOUNT_KEYS = ["××—×¨×™","× ×™×›×•×™"]        # "××—×¨×™ × ×™×›×•×™"
AUX_PAYNO_KEYS  = ["××¡","×ª×©×œ×•×"]          # "××¡' ×ª×©×œ×•×"

# ×‘×™×˜×•×™×™×/×§×‘×•×¢×™× ×œ×œ×•×’×™×§×”
RULES_FILE = "rules_store.json"
TRANSFER_CODE = 485
TRANSFER_PHRASE = "×”×¢×‘' ×‘××§×‘×¥-× ×˜"
STANDING_CODES = {469, 515}
OVRC_CODES = {120, 175}
AMOUNT_EPS = 0.00  # ×”×ª×××” ××“×•×™×§×ª ×‘×¡×›×•××™×

# ---------------- ×¢×–×¨ ×œ× ×¨××•×œ ----------------
def normalize_text(s):
    if s is None: return ""
    t = str(s)
    t = t.replace("'", "").replace('"', "").replace("â€™", "").replace("`", "")
    t = t.replace("-", " ").replace("â€“", " ").replace("Ö¾", " ")
    t = re.sub(r"\s+", " ", t)
    return t.strip()

def normalize_date(series):
    def f(x):
        if pd.isna(x): return pd.NaT
        if isinstance(x,(pd.Timestamp, datetime)): return pd.Timestamp(x.date())
        return pd.to_datetime(x, dayfirst=True, errors="coerce").normalize()
    return series.apply(f)

def to_number(series):
    s = (series.astype(str)
         .str.replace(",","", regex=False)
         .str.replace("â‚ª","", regex=False)
         .str.replace("\u200f","", regex=False)
         .str.replace("\u200e","", regex=False)
         .str.strip())
    return pd.to_numeric(s, errors="coerce")

def ref_starts_with_ov_rc(val):
    t = (str(val) if val is not None else "").strip().upper()
    return t.startswith("OV") or t.startswith("RC")

def exact_or_contains(df, names):
    for n in names:
        if n in df.columns:
            return n
    for n in names:
        for c in df.columns:
            if isinstance(c, str) and n in c:
                return c
    return None

def ws_to_df(ws):
    rows = list(ws.iter_rows(values_only=True))
    if not rows:
        return pd.DataFrame()
    header = None; start = 0
    for i, r in enumerate(rows):
        if any(x is not None for x in r):
            header = [str(x).strip() if x is not None else "" for x in r]; start = i+1; break
    if header is None:
        return pd.DataFrame()
    data = [tuple(list(row)[:len(header)]) for row in rows[start:]]
    return pd.DataFrame(data, columns=header)

# ---------------- ×˜×¢×™× ×ª ×›×œ×œ×™×/×©××™×¨×” ××ª××©×›×ª ----------------
def load_rules_from_disk():
    if os.path.exists(RULES_FILE):
        try:
            with open(RULES_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            name_map = { normalize_text(k): v for k, v in data.get("name_map", {}).items() }
            amount_map = { float(k): v for k, v in data.get("amount_map", {}).items() }
            return name_map, amount_map
        except Exception:
            pass
    # ×‘×¡×™×¡ ×× ××™×Ÿ ×§×•×‘×¥
    return { normalize_text(k): v for k, v in RAW_NAME_MAP.items() }, dict(BASE_AMOUNT_MAP)

def save_rules_to_disk(name_map, amount_map):
    try:
        with open(RULES_FILE, "w", encoding="utf-8") as f:
            json.dump({"name_map": name_map, "amount_map": amount_map}, f, ensure_ascii=False, indent=2)
        return True
    except Exception:
        return False

if "name_map" not in st.session_state or "amount_map" not in st.session_state:
    nm, am = load_rules_from_disk()
    st.session_state.name_map = nm
    st.session_state.amount_map = am

def rules_excel_bytes():
    out = io.BytesIO()
    with pd.ExcelWriter(out, engine="xlsxwriter") as w:
        pd.DataFrame(
            {"by_name": list(st.session_state.name_map.keys()),
             "××¡' ×¡×¤×§": list(st.session_state.name_map.values())}
        ).to_excel(w, index=False, sheet_name="by_name")
        pd.DataFrame(
            {"×¡×›×•×": list(st.session_state.amount_map.keys()),
             "××¡' ×¡×¤×§": list(st.session_state.amount_map.values())}
        ).to_excel(w, index=False, sheet_name="by_amount")
    return out.getvalue()

# ---------------- UI â€“ ×¢×“×›×•×Ÿ ×›×œ×œ×™ VLOOKUP (×¢× ×©××™×¨×”) ----------------
with st.expander("âš™ï¸ ×¢×“×›×•×Ÿ â€“ ×›×œ×œ×™ VLOOKUP ×§×‘×•×¢×™× ×•××•×¨×—×‘×™× (×¢× ×©××™×¨×”)", expanded=False):
    st.write("×¢×“×›×•×Ÿ ×œ×¤×™ **×¤×¨×˜×™× (×©×)** ××• ×œ×¤×™ **×¡×›×•×**. × ×©××¨ ×œÖ¾`rules_store.json` ×œ×©×™××•×© ×—×•×–×¨.")

    mode = st.radio("×¡×•×’ ×¢×“×›×•×Ÿ", ["×œ×¤×™ ×¤×¨×˜×™× (×©×)", "×œ×¤×™ ×¡×›×•×"], horizontal=True)

    if mode == "×œ×¤×™ ×¤×¨×˜×™× (×©×)":
        name_input = st.text_input("×¤×¨×˜×™× (×›××• ×‘×“×£ ×”×‘× ×§)")
        supplier_input = st.text_input("××¡' ×¡×¤×§ (×™×›×•×œ ×œ×”×™×•×ª ×’× ×˜×§×¡×˜, ×œ××©×œ 67-1)")
        cols = st.columns([1,1,1,1])
        if cols[0].button("â• ×”×•×¡×£/×¢×“×›×Ÿ"):
            k = normalize_text(name_input)
            if k and supplier_input:
                st.session_state.name_map[k] = supplier_input
                save_rules_to_disk(st.session_state.name_map, st.session_state.amount_map)
                st.success(f"×”×›×œ×œ × ×©××¨: '{k}' â†’ {supplier_input}")
        if cols[1].button("ğŸ—‘ï¸ ××—×™×§×”"):
            k = normalize_text(name_input)
            if k in st.session_state.name_map:
                del st.session_state.name_map[k]
                save_rules_to_disk(st.session_state.name_map, st.session_state.amount_map)
                st.warning(f"×”×›×œ×œ × ××—×§: '{k}'")
        if cols[2].button("ğŸ’¾ ×©××•×¨ ×™×“× ×™×ª"):
            save_rules_to_disk(st.session_state.name_map, st.session_state.amount_map)
            st.info("× ×©××¨ ×œ×§×•×‘×¥ rules_store.json")
        st.dataframe(pd.DataFrame({"by_name": list(st.session_state.name_map.keys()),
                                   "××¡' ×¡×¤×§": list(st.session_state.name_map.values())}),
                     use_container_width=True, height=260)

    else:  # ×œ×¤×™ ×¡×›×•×
        amount_input = st.number_input("×¡×›×•× (×™×—×•×©×‘ ×‘×¢×¨×š ××•×—×œ×˜)", step=0.01, format="%.2f")
        supplier_input2 = st.text_input("××¡' ×¡×¤×§", key="amount_supplier")
        cols = st.columns([1,1,1,1])
        if cols[0].button("â• ×”×•×¡×£/×¢×“×›×Ÿ", key="add_amount"):
            key_amt = round(abs(float(amount_input)), 2)
            if key_amt and supplier_input2:
                st.session_state.amount_map[key_amt] = supplier_input2
                save_rules_to_disk(st.session_state.name_map, st.session_state.amount_map)
                st.success(f"×”×›×œ×œ × ×©××¨: {key_amt} â†’ {supplier_input2}")
        if cols[1].button("ğŸ—‘ï¸ ××—×™×§×”", key="del_amount"):
            key_amt = round(abs(float(amount_input)), 2)
            if key_amt in st.session_state.amount_map:
                del st.session_state.amount_map[key_amt]
                save_rules_to_disk(st.session_state.name_map, st.session_state.amount_map)
                st.warning(f"×”×›×œ×œ × ××—×§: {key_amt}")
        if cols[2].button("ğŸ’¾ ×©××•×¨ ×™×“× ×™×ª", key="save_amount"):
            save_rules_to_disk(st.session_state.name_map, st.session_state.amount_map)
            st.info("× ×©××¨ ×œ×§×•×‘×¥ rules_store.json")
        st.dataframe(pd.DataFrame({"×¡×›×•×": list(st.session_state.amount_map.keys()),
                                   "××¡' ×¡×¤×§": list(st.session_state.amount_map.values())})
                     .sort_values("×¡×›×•×"), use_container_width=True, height=260)

    st.divider()
    c1, c2, c3, c4 = st.columns([1,1,1,2])
    c1.download_button("â¬‡ï¸ ×™×™×¦×•× JSON", data=json.dumps({
                            "name_map": st.session_state.name_map,
                            "amount_map": st.session_state.amount_map
                        }, ensure_ascii=False, indent=2).encode("utf-8"),
                        file_name="rules_store.json", mime="application/json")
    uploaded_rules = c2.file_uploader("â¬†ï¸ ×™×™×‘×•× JSON", type=["json"], label_visibility="collapsed")
    if c3.button("×™×™×‘×•× ×•×”×—×œ×¤×”"):
        if uploaded_rules is not None:
            try:
                data = json.loads(uploaded_rules.read().decode("utf-8"))
                nm = { normalize_text(k): v for k, v in data.get("name_map", {}).items() }
                am = { float(k): v for k, v in data.get("amount_map", {}).items() }
                st.session_state.name_map = nm
                st.session_state.amount_map = am
                save_rules_to_disk(nm, am)
                st.success("×”×›×œ×œ×™× ×™×•×‘××• ×•× ×©××¨×• ×‘×”×¦×œ×—×”.")
            except Exception as e:
                st.error(f"×©×’×™××” ×‘×™×™×‘×•×: {e}")
    if c4.button("ğŸ”„ ×©××•×¨ ×¢×“×›×•× ×™× ×œ×©×™××•×© ×¢×ª×™×“×™"):
        if save_rules_to_disk(st.session_state.name_map, st.session_state.amount_map):
            st.success("× ×©××¨ ×‘×”×¦×œ×—×” ×œÖ¾rules_store.json")

st.divider()

# ---------------- ×¤×•× ×§×¦×™×•×ª ×œ×•×’×™×§×” ----------------
def process_workbook(main_bytes, aux_bytes=None):
    """××¢×‘×“ ××ª ×§×•×‘×¥ ×”××§×•×¨ + (××•×¤×¦×™×•× ×œ×™×ª) ×§×•×‘×¥ ×¢×–×¨ ×œ×”×¢×‘×¨×•×ª, ×•××—×–×™×¨ Bytes ×©×œ ××§×¡×œ ××¢×•×“×›×Ÿ + ×˜×‘×œ×ª ×¡×™×›×•×."""
    # ×˜×¢×Ÿ ××ª ×—×•×‘×¨×ª ×”××§×•×¨
    wb_in = load_workbook(io.BytesIO(main_bytes), data_only=True, read_only=True)

    out_stream = io.BytesIO()
    summary_rows, standing_rows = [], []

    # ===== ×©×œ×‘ 1: ××¢×‘×¨ ×¢×œ ×›×œ ×”×’×™×œ×™×•× ×•×ª =====
    with pd.ExcelWriter(out_stream, engine="xlsxwriter") as writer:
        for ws in wb_in.worksheets:
            df = ws_to_df(ws)
            df_save = df.copy()
            if df.empty:
                pd.DataFrame().to_excel(writer, index=False, sheet_name=ws.title)
                continue

            # ××™×ª×•×¨ ×¢××•×“×•×ª
            col_match     = exact_or_contains(df, MATCH_COL_CANDS) or df.columns[0]
            col_bank_code = exact_or_contains(df, BANK_CODE_CANDS)
            col_bank_amt  = exact_or_contains(df, BANK_AMT_CANDS)
            col_books_amt = exact_or_contains(df, BOOKS_AMT_CANDS)
            col_ref       = exact_or_contains(df, REF_CANDS)
            col_date      = exact_or_contains(df, DATE_CANDS)
            col_details   = exact_or_contains(df, DETAILS_CANDS)

            match_values = df_save[col_match].copy() if col_match in df_save.columns else pd.Series([0]*len(df_save))
            if match_values.isna().any():
                match_values = match_values.fillna(0)

            # × ×¨××•×œ ×©×“×•×ª
            _date      = normalize_date(pd.to_datetime(df[col_date], errors="coerce")) if col_date else pd.Series([pd.NaT]*len(df))
            _bank_amt  = to_number(df[col_bank_amt])  if col_bank_amt  else pd.Series([np.nan]*len(df))
            _books_amt = to_number(df[col_books_amt]) if col_books_amt else pd.Series([np.nan]*len(df))
            _bank_code = to_number(df[col_bank_code]) if col_bank_code else pd.Series([np.nan]*len(df))
            _ref       = df[col_ref].astype(str).fillna("") if col_ref else pd.Series([""]*len(df))
            _details   = df[col_details].astype(str).fillna("") if col_details else pd.Series([""]*len(df))

            # ===== ×”×ª×××” 1 â€“ OV/RC ×§×¤×“× ×™×ª 1:1 =====
            applied_ovrc = False; pairs = 0
            if all([col_bank_code, col_bank_amt, col_books_amt, col_ref, col_date]):
                applied_ovrc = True
                # ××•×¢××“×™× ×¡×¤×¨×™×: +, OV/RC
                books_candidates = [
                    j for j in range(len(df))
                    if pd.notna(_books_amt.iat[j]) and _books_amt.iat[j] > 0
                    and pd.notna(_date.iat[j]) and ref_starts_with_ov_rc(_ref.iat[j])
                ]
                # ×§×‘×•×¦×•×ª ×œ×¤×™ (×¡×›×•× ××•×—×œ×˜, ×ª××¨×™×š) â€“ ×—×™×™×‘ 1:1
                # × ×‘× ×” ××¤×ª×— ×œ×›×œ ×¦×“
                bank_keys  = {}
                books_keys = {}
                for i in range(len(df)):
                    if pd.notna(_bank_code.iat[i]) and int(_bank_code.iat[i]) in OVRC_CODES \
                       and pd.notna(_bank_amt.iat[i]) and _bank_amt.iat[i] < 0 \
                       and pd.notna(_date.iat[i]):
                        k = (round(abs(float(_bank_amt.iat[i])),2), _date.iat[i])
                        bank_keys.setdefault(k, []).append(i)
                for j in books_candidates:
                    k = (round(abs(float(_books_amt.iat[j])),2), _date.iat[j])
                    books_keys.setdefault(k, []).append(j)
                # ×”×ª×××” ×§×¤×“× ×™×ª: ×¨×§ ××¤×ª×—×•×ª ×©××•×¤×™×¢×™× ×¤×¢× ××—×ª ×‘×›×œ ×¦×“
                for k, b_idx in bank_keys.items():
                    if len(b_idx) == 1 and len(books_keys.get(k, [])) == 1:
                        i = b_idx[0]; j = books_keys[k][0]
                        if match_values.iat[i] in (0,2) and match_values.iat[j] in (0,2):  # ×œ× ×œ×“×¨×•×¡ 3/1
                            match_values.iat[i] = 1
                            match_values.iat[j] = 1
                            pairs += 1

            # ===== ×”×ª×××” 2 â€“ ×”×•×¨××•×ª ×§×‘×¢ (469/515) =====
            applied_standing = False; flagged = 0
            if all([col_bank_code, col_details, col_bank_amt]):
                applied_standing = True
                for i in range(len(df)):
                    code = _bank_code.iat[i]
                    if pd.notna(code) and int(code) in STANDING_CODES:
                        if match_values.iat[i] in (0,):   # ×œ× ×œ×“×¨×•×¡ 1/3
                            match_values.iat[i] = 2
                            flagged += 1
                            standing_rows.append({"×¤×¨×˜×™×": _details.iat[i],
                                                  "×¡×›×•×": float(_bank_amt.iat[i]) if pd.notna(_bank_amt.iat[i]) else np.nan})

            # ×¡×™×•× ×’×™×œ×™×•×Ÿ
            df_out = df_save.copy()
            df_out[col_match] = match_values
            df_out.to_excel(writer, index=False, sheet_name=ws.title)

            summary_rows.append({
                "×’×™×œ×™×•×Ÿ": ws.title,
                "OV/RC ×‘×•×¦×¢": "×›×Ÿ" if applied_ovrc else "×œ×",
                "×–×•×’×•×ª ×©×¡×•×× ×• 1": pairs,
                "×”×•×¨××ª ×§×‘×¢ ×‘×•×¦×¢": "×›×Ÿ" if applied_standing else "×œ×",
                "×©×•×¨×•×ª ×©×¡×•×× ×• 2": flagged,
                "×¢××•×“×ª ×”×ª×××”": col_match
            })

        # ===== ×’×™×œ×™×•×Ÿ ×”×•×¨××ª ×§×‘×¢ ×¡×¤×§×™× (××”×©×•×¨×•×ª ×©×¡×•×× ×• 2) =====
        st_df = pd.DataFrame(standing_rows)
        if not st_df.empty:
            def map_supplier(name, amount):
                # 1) ×œ×¤×™ ×©×
                s = normalize_text(name)
                if s in st.session_state.name_map:
                    return st.session_state.name_map[s]
                for key in sorted(st.session_state.name_map.keys(), key=len, reverse=True):
                    if key and key in s:
                        return st.session_state.name_map[key]
                # 2) ×œ×¤×™ ×¡×›×•× ××•×—×œ×˜
                try:
                    val = round(abs(float(amount)), 2)
                    return st.session_state.amount_map.get(val, "")
                except Exception:
                    return ""

            st_df["××¡' ×¡×¤×§"] = st_df.apply(lambda r: map_supplier(r["×¤×¨×˜×™×"], r["×¡×›×•×"]), axis=1)
            # ×©×•×¨×•×ª ×¨×’×™×œ×•×ª: ×—×•×‘×” ×‘×œ×‘×“; ×©×•×¨×ª ×¡×™×›×•× 20001 ×ª×”×™×” ×‘×–×›×•×ª
            st_df["×¡×›×•× ×—×•×‘×”"] = st_df["×¡×›×•×"].apply(lambda x: abs(x) if pd.notna(x) else 0.0)
            st_df["×¡×›×•× ×–×›×•×ª"] = 0.0

            # ×¡×›×•× ×—×•×‘×” ×¨×§ ×œ×©×•×¨×•×ª ×©×™×© ×œ×”×Ÿ ××¡' ×¡×¤×§
            total_hova_with_supplier = st_df.loc[st_df["××¡' ×¡×¤×§"].astype(str).str.len()>0, "×¡×›×•× ×—×•×‘×”"].sum()

            vk = st_df[["×¤×¨×˜×™×","×¡×›×•×","××¡' ×¡×¤×§","×¡×›×•× ×—×•×‘×”","×¡×›×•× ×–×›×•×ª"]].copy()
            # ×©×•×¨×ª ×¡×™×›×•× 20001 â€“ ×–×›×•×ª ×‘×œ×‘×“
            vk = pd.concat([vk, pd.DataFrame([{
                "×¤×¨×˜×™×":"×¡×”\"×› ×–×›×•×ª â€“ ×¢× ××¡' ×¡×¤×§",
                "×¡×›×•×":0.0,
                "××¡' ×¡×¤×§":20001,
                "×¡×›×•× ×—×•×‘×”":0.0,
                "×¡×›×•× ×–×›×•×ª":round(total_hova_with_supplier,2)
            }])], ignore_index=True)
        else:
            vk = pd.DataFrame(columns=["×¤×¨×˜×™×","×¡×›×•×","××¡' ×¡×¤×§","×¡×›×•× ×—×•×‘×”","×¡×›×•× ×–×›×•×ª"])

        vk.to_excel(writer, index=False, sheet_name="×”×•×¨××ª ×§×‘×¢ ×¡×¤×§×™×")

    # ===== ×©×œ×‘ 2: ×¢×™×¦×•×‘ (RTL, ×¦×‘×™×¢×”, ×©×•×¨×ª 20001 ××•×“×’×©×ª) =====
    wb_out = load_workbook(io.BytesIO(out_stream.getvalue()))
    for s in wb_out.worksheets:
        s.sheet_view.rightToLeft = True

    ws_so = wb_out["×”×•×¨××ª ×§×‘×¢ ×¡×¤×§×™×"]
    headers = {cell.value: idx for idx, cell in enumerate(ws_so[1], start=1)}
    col_supplier = headers.get("××¡' ×¡×¤×§")
    col_details  = headers.get("×¤×¨×˜×™×")
    col_amount   = headers.get("×¡×›×•×")
    col_debit    = headers.get("×¡×›×•× ×—×•×‘×”")
    col_credit   = headers.get("×¡×›×•× ×–×›×•×ª")

    orange = PatternFill(start_color="FFF2CC", end_color="FFF2CC", fill_type="solid")
    if col_supplier:
        # ×¦×‘×™×¢×” ×›×ª×•××” ×œ×©×•×¨×•×ª ×œ×œ× ××¡' ×¡×¤×§ (×œ××¢×˜ ×”×©×•×¨×” ×”××—×¨×•× ×” ×× ×”×™× 20001)
        for r in range(2, ws_so.max_row+1):
            v = ws_so.cell(row=r, column=col_supplier).value
            if v in ("", None):
                for c in range(1, ws_so.max_column+1):
                    ws_so.cell(row=r, column=c).fill = orange

    # ××—×™×§×” ×©×œ 20001 ×›×¤×•×œ×™× ×× ×§×™×™××™×
    dels = []
    for r in range(2, ws_so.max_row+1):
        v = ws_so.cell(row=r, column=col_supplier).value
        if v == 20001 or (isinstance(v,str) and v.strip() == "20001"):
            dels.append(r)
    for k, r in enumerate(dels[:-1]):  # × ×©××™×¨ ××ª ×”××—×¨×•×Ÿ
        ws_so.delete_rows(r-k, 1)

    # ×”×“×’×©×” ×œ×©×•×¨×” ×”××—×¨×•× ×” (×¡×™×›×•×)
    for cell in ws_so[ws_so.max_row]:
        cell.font = Font(bold=True)

    # ===== ×©×œ×‘ 3: ×”×ª×××” 3 (×”×¢×‘×¨×•×ª ×¡×¤×§×™×) â€“ ××ª×‘×¦×¢ ××—×¨×™ ×›×ª×™×‘×ª ×”×§×‘×¦×™× ×›×“×™ ×œ× ×œ×¤×¡×¤×¡ ×¢××•×“×•×ª) =====
    # × ×˜×¢×Ÿ ××—×“×© ××ª ×”-DataSheet ×œ×ª×•×š DF, × ×‘×¦×¢ ×¡×™××•×Ÿ 3 ×•× ×“×¨×•×¡ ××ª ×”×’×™×œ×™×•×Ÿ ×‘×œ×‘×“.
    if aux_bytes is not None:
        # ×¢×–×¨ â€“ ×§×¨×™××” ×•×’×–×™×¨×ª ×¢××•×“×•×ª
        aux_xl = load_workbook(io.BytesIO(aux_bytes), data_only=True, read_only=True)
        aux_ws = aux_xl.worksheets[0]
        aux_df = ws_to_df(aux_ws)

        # ××¦× ×¢××•×“×•×ª ×‘×§×•×‘×¥ ×¢×–×¨
        def pick_col(df, keys):
            for c in df.columns:
                s = str(c)
                if all(k in s for k in keys):
                    return c
            return None

        c_dt  = pick_col(aux_df, AUX_DATE_KEYS)
        c_amt = pick_col(aux_df, AUX_AMOUNT_KEYS)
        c_pay = pick_col(aux_df, AUX_PAYNO_KEYS)

        aux_dt  = pd.to_datetime(aux_df[c_dt], errors="coerce") if c_dt else pd.Series([pd.NaT]*len(aux_df))
        aux_amt = pd.to_numeric(aux_df[c_amt], errors="coerce").round(2) if c_amt else pd.Series([np.nan]*len(aux_df))
        aux_pay = aux_df[c_pay].astype(str).str.strip() if c_pay else pd.Series([""]*len(aux_df))

        # ×§×™×‘×•×¥ ×œ×¤×™ ×ª××¨×™×š+×©×¢×” (Timestamp ××œ×) â€“ ×¡×›×•× "××—×¨×™ × ×™×›×•×™"
        grouped = (pd.DataFrame({"_dt": aux_dt, "_amt": aux_amt})
                     .dropna(subset=["_dt"])
                     .groupby("_dt")["_amt"].sum().round(2)
                     .to_dict())
        pays_by_dt = (pd.DataFrame({"_dt": aux_dt, "_pay": aux_pay})
                        .groupby("_dt")["_pay"]
                        .apply(lambda s: set(s.dropna().astype(str)))
                        .to_dict())

        # × ×˜×¢×Ÿ DF ×©×œ DataSheet ××ª×•×š ×”×§×•×‘×¥ ×©×–×” ×¢×ª×” ×™×™×¦×¨× ×•
        ds_ws = wb_out["DataSheet"]
        ds_df = ws_to_df(ds_ws)

        # ×¢××•×“×•×ª ×§×¨×™×˜×™×•×ª
        ds_col_match     = exact_or_contains(ds_df, MATCH_COL_CANDS) or ds_df.columns[0]
        ds_col_bank_code = exact_or_contains(ds_df, BANK_CODE_CANDS)
        ds_col_bank_amt  = exact_or_contains(ds_df, BANK_AMT_CANDS)
        ds_col_details   = exact_or_contains(ds_df, DETAILS_CANDS)
        ds_col_ref       = exact_or_contains(ds_df, REF_CANDS)

        ds_match   = pd.to_numeric(ds_df[ds_col_match], errors="coerce").fillna(0).astype(int)
        ds_code    = to_number(ds_df[ds_col_bank_code])
        ds_amt     = to_number(ds_df[ds_col_bank_amt]).round(2)
        ds_details = ds_df[ds_col_details].astype(str).fillna("")
        ds_ref     = ds_df[ds_col_ref].astype(str).fillna("")

        # ××•×¢××“×™× ×‘×¦×“ ×”×‘× ×§: 485 + ×”×˜×§×¡×˜ + ×¡×›×•× ×‘×“×£ > 0
        bank_candidates = (ds_code == TRANSFER_CODE) & \
                          (ds_amt > 0) & \
                          (ds_details.str.contains(TRANSFER_PHRASE, na=False))

        # ×”×ª×××” ×œ×¤×™ ×¡×›×•× ×‘×œ×‘×“ (××™×Ÿ ×‘×“×™×§×ª ×ª××¨×™×š ×‘×¦×“ ×”×‘× ×§)
        mark_bank = set(); mark_link = set()
        for dt, gsum in grouped.items():
            hits = ds_df.index[bank_candidates & (ds_amt.abs().round(2) == abs(gsum))].tolist()
            if hits:
                mark_bank.update(hits)
                payset = pays_by_dt.get(dt, set())
                if payset:
                    link_rows = ds_df.index[ds_ref.astype(str).isin(payset)].tolist()
                    mark_link.update(link_rows)

        # ×¡×™××•×Ÿ 3 â€“ ×œ× ×œ×“×¨×•×¡ 1
        for i in sorted(mark_bank):
            if ds_match.iat[i] in (0,2):
                ds_match.iat[i] = 3
        for i in sorted(mark_link):
            if ds_match.iat[i] in (0,2):
                ds_match.iat[i] = 3

        # ×›×ª×™×‘×” ×—×–×¨×” ×œ×’×œ×™×•×Ÿ DataSheet ×‘×œ×‘×“
        ds_df_out = ds_df.copy()
        ds_df_out[ds_col_match] = ds_match
        # ××—×œ×™×¤×™× ×ª×•×›×Ÿ ×’×œ×™×•×Ÿ
        for _ in range(ds_ws.max_row, 1, -1):
            ds_ws.delete_rows(2, 1)
        for r in ds_df_out.itertuples(index=False):
            ds_ws.append(list(r))

    # ×”×—×–×¨×ª Bytes
    final_bytes = io.BytesIO()
    wb_out.save(final_bytes)
    # ×˜×‘×œ×ª ×¡×™×›×•× ×§×¦×¨×” (××•×¤×§×ª ××”×¨××©×™×ª, ×œ×¤× ×™ ×”×ª×××” 3)
    summary_df = pd.DataFrame(summary_rows)
    return final_bytes.getvalue(), summary_df

# ---------------- UI â€“ ×”×¢×œ××•×ª ×•×”×¨×¦×” ----------------
colA, colB = st.columns([2,2])
uploaded_main = colA.file_uploader("×‘×—×¨×™ ×§×•×‘×¥ ××§×¡×œ ××§×•×¨ (xlsx) â€“ ×›×•×œ×œ DataSheet", type=["xlsx"])
uploaded_aux  = colB.file_uploader("(××•×¤×¦×™×•× ×œ×™) ×§×•×‘×¥ ×¢×–×¨ ×œ×”×¢×‘×¨×•×ª â€“ '×ª××¨×™×š ×¤×¨×™×§×”' (×ª××¨×™×š+×©×¢×”), '××—×¨×™ × ×™×›×•×™', '××¡' ×ª×©×œ×•×'", type=["xlsx"])

if st.button("×”×¨×¦×”"):
    if uploaded_main is None:
        st.error("× × ×œ×”×¢×œ×•×ª ×§×•×‘×¥ ××§×•×¨ (xlsx) ×¢× ×’×™×œ×™×•×Ÿ DataSheet.")
    else:
        with st.spinner("××¢×‘×“..."):
            out_bytes, summary = process_workbook(uploaded_main.read(),
                                                  uploaded_aux.read() if uploaded_aux else None)
        st.success("××•×›×Ÿ! ××¤×©×¨ ×œ×”×•×¨×™×“ ××ª ×”×§×•×‘×¥ ×”××¢×•×“×›×Ÿ.")
        if not summary.empty:
            st.dataframe(summary, use_container_width=True)
        st.download_button("â¬‡ï¸ ×”×•×¨×“×ª ×§×•×‘×¥ ××¢×•×“×›×Ÿ",
                           data=out_bytes,
                           file_name="×”×ª×××•×ª_1_2_3_+_×”×•×¨××ª_×§×‘×¢.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
else:
    st.caption("×˜×™×¤: ×”×›×œ×œ×™× × ×©××¨×™× ××•×˜×•××˜×™×ª ×œÖ¾rules_store.json. ××¤×©×¨ ×’× ×œ×™×™×¦×/×œ×™×™×‘× JSON ×œ×’×™×‘×•×™.")
# ==== ×¢×–×¨ ××™× ×™××œ×™ ====
import re
import numpy as np
import pandas as pd

AMOUNT_TOL_4 = 0.20   # ×˜×•×œ×¨× ×¡ ×œ×¡×›×•××™× ×‘×›×œ×œ 4
CHECK_CODE   = 493    # ×§×•×“ ×¤×¢×•×œ×” ×‘× ×§ ×œ×©×™×§×™ ×¡×¤×§×™×

def _only_digits(s: str) -> str:
    """××—×–×™×¨ ×¡×¤×¨×•×ª ×‘×œ×‘×“ ×œ×œ× ××¤×¡×™× ××•×‘×™×œ×™× (×œ×–×™×”×•×™ ××¡××›×ª××•×ª)."""
    s = "" if s is None else str(s)
    d = re.sub(r"\D", "", s).lstrip("0")
    return d or "0"

def _to_number(x):
    """×”××¨×ª ×¢×¨×›×™× ××¡×¤×¨×™×™× ×‘××•×¤×Ÿ ×¡×œ×—× ×™ (×¢× ×¤×¡×™×§×™×/××˜×‘×¢)."""
    if pd.isna(x): return np.nan
    s = str(x).replace(",", "").replace("â‚ª", "").strip()
    try:
        return float(s)
    except Exception:
        m = re.findall(r"[-+]?\d+(?:\.\d+)?", s)
        return float(m[0]) if m else np.nan
# ---------------- ×¢×–×¨ ××™× ×™××œ×™ ----------------
import re
import numpy as np
import pandas as pd




